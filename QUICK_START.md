# Quick Start: New Features

## ðŸŽ¯ What's New

### âš¡ Streaming TTS (Priority 1)
**Reduces time-to-first-word from 5s â†’ 2s**

The bot now starts speaking the first sentence immediately while synthesizing the rest, instead of waiting for the entire response.

**Status:** âœ… Enabled by default

### ðŸŽ¤ Wake Word Detection (Priority 2)  
**Reduces false triggers and API costs**

The bot only processes speech that starts with "Jarvis" or other configured wake phrases.

**Status:** âš ï¸ Disabled by default (opt-in)

---

## ðŸš€ Quick Enable/Disable

Edit `./jarvis-voice/.env`:

```bash
# Streaming TTS (already enabled)
STREAMING_TTS_ENABLED=true    # Change to false to disable

# Wake Word Detection (currently disabled)
WAKE_WORD_ENABLED=true        # Change to true to enable
WAKE_WORD_PHRASES=jarvis,hey jarvis,hey travis,yo jarvis
```

After changing `.env`, restart the bot:
```bash
cd ./jarvis-voice
npm start
```

---

## ðŸ“Š Expected Behavior

### Streaming TTS Enabled
- **Long response (>100 chars):**  
  First sentence plays within 1-2s, rest queues and plays seamlessly
  
- **Short response (<100 chars):**  
  Uses batch mode (no perceptible difference, already fast)

### Wake Word Enabled
- **"Jarvis, what's the weather?"**  
  â†’ Bot responds: "Yes sir." â†’ Processes command
  
- **"Random conversation"**  
  â†’ Bot ignores (no response, no API call)

- **Wake word stripped from transcript**  
  Brain sees: "what's the weather?" not "Jarvis, what's the weather?"

---

## ðŸ› Troubleshooting

### Streaming TTS Issues
**Problem:** Audio sounds choppy or cuts off early  
**Solution:** Set `STREAMING_TTS_ENABLED=false` to revert to batch mode

**Problem:** Long silence before first sentence  
**Solution:** Check TTS provider (Edge TTS should be fast, OpenAI fallback is slower)

### Wake Word Issues
**Problem:** Bot ignores all commands  
**Solution:** Either say "Jarvis" at the start, or set `WAKE_WORD_ENABLED=false`

**Problem:** Wake word not detected  
**Solution:** Check Whisper transcription logs for what it heard. Add misheard variants to `WAKE_WORD_PHRASES`

---

## ðŸ“ Logs to Watch

When testing, look for these log lines:

### Streaming TTS
```
ðŸ”Š Streaming TTS (sentence-level chunking)...
ðŸ“„ Split into 3 sentences
ðŸ”Š Playing queued segment 1/3
â±ï¸  Total pipeline to first audio: 1842ms
```

### Wake Word
```
ðŸ“ Raw transcript: "Jarvis what's the weather"
ðŸŽ¯ Wake word detected: "jarvis"
ðŸŽµ Playing wake confirmation
ðŸ“ Cleaned transcript: "what's the weather"
```

Or if no wake word:
```
ðŸ“ Raw transcript: "random conversation"
ðŸš« No wake word detected in: "random conversation"
â­ï¸  No wake word, skipping processing
```

---

## ðŸ§ª Test Commands

### Test Streaming TTS
Say a long request to trigger sentence chunking:
> "Jarvis, explain the difference between microservices and monolithic architectures in detail, including the trade-offs and when each is appropriate."

You should hear the first sentence within 2 seconds.

### Test Wake Word
1. Enable: `WAKE_WORD_ENABLED=true`
2. Restart bot
3. Say: **"Jarvis, what time is it?"** â†’ Should respond
4. Say: **"What time is it?"** (no wake word) â†’ Should ignore

---

## ðŸ”„ Rollback

If you need to revert to the old behavior:

```bash
# .env
STREAMING_TTS_ENABLED=false
WAKE_WORD_ENABLED=false
```

Or restore from git:
```bash
cd ./jarvis-voice
git checkout HEAD~1 -- src/
```

---

## ðŸ“š Full Documentation

- **Implementation details:** See `IMPLEMENTATION_SUMMARY.md`
- **Roadmap:** See `TODO.md` (P1 and P2 are marked complete)
- **Configuration:** See `.env.example` or `.env`

---

**Ready to test!** Start the bot with `npm start` and try the new features.
